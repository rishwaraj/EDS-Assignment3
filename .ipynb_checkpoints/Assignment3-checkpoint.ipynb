{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Web Scraping\n",
    "\n",
    "For this assignment, you are required to scrape data from e-commerce or other websites such as [Lelong](http://www.lelong.com.my), [Lazada](http://www.lazada.com.my/), [Mudah](http://www.mudah.my/), [iProperty](https://www.iproperty.com.my/), [Booking](http://www.booking.com), [Expedia](https://www.expedia.com.my/) etc.\n",
    "\n",
    "You are required to fork this Jupyter Notebook from my Github [here](https://github.com/kuanhoong/EDS-Assignment3 ) and then scrape the latest 1000 items from one of the website mentioned above. The scraped data should include:\n",
    "\n",
    "* Product Name/Product Title\n",
    "* Amount/Price\n",
    "* Brand\n",
    "* Comments/Reviews\n",
    "* Number of views\n",
    "\n",
    "In addition, you are required to export the scraped data to dataframe format and also save a copy in csv format. Upon successful extracting data to dataframe, you are required to do a data analysis on the data. \n",
    "\n",
    "Your analysis should provide answers to the following questions:\n",
    "* What do you think is interesting about this data? Tell a story about some interesting thing you have discovered by looking at the data.\n",
    "* Visualize your data with matplotlib or with folium library package.\n",
    "\n",
    "For example, you might consider whether there is a difference in pricings at different times doing the day or city, or whether other factors that influnced the pricings etc. Another thing you might consider is whether there is a relationship between the pricing and number of reviews or comments.\n",
    "\n",
    "Show your analysis workflow in your Jupyter notebook.\n",
    "\n",
    "The final submission should be pushed back to your respective Github account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folium\n",
    "\n",
    "[Folium](https://github.com/python-visualization/folium) makes it easy to visualize data that's been manipulated in Python on an interactive Leaflet map. It enables both the binding of data to a map for choropleth visualizations as well as passing Vincent/Vega visualizations as markers on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapit = None\n",
    "latlon = [ (3.144473, 101.708722), (3.144473, 101.708722),(3.135732, 101.686989),(3.0731, 101.6078)]\n",
    "for coord in latlon:\n",
    "    mapit = folium.Map( location=[ coord[0], coord[1] ] )\n",
    "    # Markers are the pin-like icon on the map\n",
    "    folium.Marker([3.144473, 101.708722], icon=folium.Icon(color='blue',icon='star'), popup='Federal Hotel').add_to(mapit)\n",
    "    folium.Marker([3.156374, 101.714579], icon=folium.Icon(color='green',icon='info-sign') , popup='Mandarin Oriental').add_to(mapit)\n",
    "    folium.Marker([3.135732, 101.686989], icon=folium.Icon(color='red',icon='star') , popup='Le Meridien').add_to(mapit)\n",
    "    folium.Marker([3.0731, 101.6078], icon=folium.Icon(color='blue',icon='star') , popup='Sunway Pyramid').add_to(mapit)\n",
    "mapit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW MacBook Pro 13 13.3 A1706 A1708 Matte Frosted Hard Case Cover\n",
      "RM 28.00\n"
     ]
    }
   ],
   "source": [
    "# scrape from lelong\n",
    "\n",
    "# find the pattern for the first page\n",
    "url = 'https://www.lelong.com.my/catalog/all/list?TheKeyword=macbook+pro&D='\n",
    "\n",
    "# write a loop to scrape from page 1 to the last page\n",
    "\n",
    "product_name=[] # empty list c\n",
    "price_name=[]\n",
    "for page in range(1,2):\n",
    "    url_page = url+str(page)\n",
    "    #print (url_page);\n",
    "    scrape = requests.get(url_page)\n",
    "    soup = BeautifulSoup(scrape.content, 'lxml')\n",
    "    #print(soup)\n",
    "    link = soup.find_all('div',{'class':'item','class':'summary'})\n",
    "#    link1 =  soup.find_all('div',{'class':'col total', 'class':'price pull-right'})\n",
    "# Above doesn't seem to woek\n",
    "    link1 =  soup.find_all('div',{'class':'col total'})\n",
    "    #print(link);\n",
    "    #print(link1);\n",
    "    length = len(link)\n",
    "    for i in range(0,length):\n",
    "        name = link[i].a.get('title')\n",
    "        pp = link1[i].b.string\n",
    "        product_name.append(name)\n",
    "        price_name.append(pp)\n",
    "print(product_name[1])\n",
    "print(price_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### write to csv\n",
    "# convert the list to a pandas dataframe\n",
    "\n",
    "df = pd.DataFrame({'name':product_name, 'price':price_name})\n",
    "# df['price'] = df['price'].str.re\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
